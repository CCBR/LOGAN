
manifest {
    name = "CCBR/LOGAN"
    author = "CCR Collaborative Bioinformatics Resource"
    homePage = "https://github.com/CCBR/LOGAN"
    description = "whoLe genOme-sequencinG Analysis pipeliNe"
    mainScript = "main.nf"
}

includeConfig 'conf/containers.config'
includeConfig 'conf/genomes.config'
includeConfig 'conf/base.config'
includeConfig 'conf/modules.config'


params { 

    fastq_screen_conf = "${projectDir}/conf/fastq_screen.conf"
    get_flowcell_lanes = "${projectDir}/bin/scripts/flowcell_lane.py"
    splitbed= "${projectDir}/bin/split_Bed_into_equal_regions.py"
    script_genderPrediction = "${projectDir}/bin/RScripts/predictGender.R"
    script_combineSamples = "${projectDir}/bin/combineAllSampleCompareResults.R"
    script_ancestry = "${projectDir}/bin/sampleCompareAncestoryPlots.R"
    script_sequenza = "${projectDir}/bin/run_sequenza.R"
    script_freec = "${projectDir}/bin/make_freec_genome.pl"
    script_freecpaired = "${projectDir}/bin/freec_paired.pl"
    freec_significance = "${projectDir}/bin/assess_significance.R"
    freec_plot = "${projectDir}/bin/makeGraph.R"
    lofreq_convert = "${projectDir}/bin/add_gt_lofreq.sh"
    split_regions = "24" //Number of regions to split by 

    vep_cache = "/fdb/VEP/102/cache"

    //SUB WORKFLOWS to SPLIT
    gl=null
    vc=null
    sv=null
    cnv=null
    qc=null
    bam=null
    //Set all Inputs to null
    sample_sheet=null
    fastq_input=null
    bam_input=null
    BAMINPUT=null
    file_input=null

    publish_dir_mode = 'symlink'
    outdir = 'results'

}


profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }

    docker {
        docker.enabled = true
        // Avoid this error:
        //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
        // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
        // once this is established and works well, nextflow might implement this behavior as new default.
        docker.runOptions = '-u \$(id -u):\$(id -g)'
    }
    singularity {
        enabled = true
        autoMounts = true
        cacheDir = "$PWD/singularity"
        envWhitelist='https_proxy,http_proxy,ftp_proxy,DISPLAY,SLURM_JOBID'
        runOptions = '-B /gs10,/gs11,/gs12,/gs9,/spin1,/data/CCBR_Pipeliner/,/data/CCBR_Pipeliner/Pipelines/XAVIER/resources/,/data/nousomedr/,/data/CCBR/projects/,/vf/users,/gpfs,/fdb'
        }
    biowulf { 
        includeConfig 'conf/biowulf.config' 
    }
    frce { 
        includeConfig 'conf/frce.config' 
    }
    interactive { 
        includeConfig 'conf/interactive.config' 
    }
    slurm { 
        includeConfig 'conf/slurm.config' 
    }
    ci_stub { 
        includeConfig 'conf/ci_stub.config' 
    }
}
  
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.
    env {
        PYTHONNOUSERSITE = 1
        R_PROFILE_USER   = "/.Rprofile"
        R_ENVIRON_USER   = "/.Renviron"
        JULIA_DEPOT_PATH = "/usr/local/share/julia"
    }

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

    



// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}


// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')
dag {
    enabled   = true
    overwrite = true
    file      = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}
report {
    enabled   = true
    overwrite = true
    file      = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
